{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 2, MSBC.5190 Modern Artificial Intelligence S23\n",
        "\n",
        "\n",
        "**Teammates: Kersti Kammerer, Alyssa Duke, Wes Weber**\n",
        "\n",
        "**Teamname: Team1**\n",
        "\n",
        "Handout 03/10/2022 4pm, **due 03/24/2022 by 4pm**. Please submit through Canvas. Each team only needs to submit one copy.\n",
        "\n",
        "Important information about submission:\n",
        "- Write all code, text (answers), and figures in the notebook.\n",
        "- Please make sure that the submitted notebook has been run and the cell outputs are visible.\n",
        "- Please print the notebook as PDF and submit it together with the notebook. Your submission should contain two files: `homework2-teamname.ipynb` and `homework2-teamname.pdf`\n",
        "\n",
        "The goal of the homework are three folds:\n",
        "\n",
        "\n",
        "1.   Explore word embedding \n",
        "2.   Understand contextual word embedding using BERT\n",
        "3.   Text classificaiton with both traditional machine learning methods and deep learning methods\n",
        "\n",
        "**A note about GPU**: You'd better use GPU to run it, otherwise it will be quite slow to train deep learning models.  "
      ],
      "metadata": {
        "id": "CReTLT9gZZBi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, import the packages or modules required for this homework."
      ],
      "metadata": {
        "id": "zE0gwmvro7l8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# TODO: Fill in your codes                                                     #\n",
        "# Import packages or modules                                                   #\n",
        "################################################################################\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "2Ju3_EJHDU4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part I: Explore Word Embedding (15%)\n",
        "\n",
        "Word embeddings are useful representation of words that capture information about word meaning as well as location. They are used as a fundamental component for downstream NLP tasks, e.g., text classification. In this part, we will explore the embeddings produced by [GloVe (global vectors for word representation)](https://nlp.stanford.edu/projects/glove/). It is simlar to Word2Vec but differs in their underlying methodology: in GloVe, word embeddings are learned based on global word-word co-occurrence statistics. Both Word2Vec and GloVe tend to produce vector-space embeddings that perform similarly in downstream NLP tasks.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QDTrDzLXMX_X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first load the GloVe vectors"
      ],
      "metadata": {
        "id": "AlyvKW4QWHni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "# download the model and return as object ready for use\n",
        "glove_model = api.load('glove-wiki-gigaword-100') \n",
        "#load the word vectors from the model     \n",
        "glove_word_vectors = glove_model.wv                        "
      ],
      "metadata": {
        "id": "RqFT4Rz0SvMD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5e33e5f-587a-498f-ccf7-42b2b3d9c1d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-4c272531b1ec>:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  glove_word_vectors = glove_model.wv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take a look at the vocabulary size and dimensionality of the embedding space"
      ],
      "metadata": {
        "id": "tPHjODcJ7qn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('vocabulary size = ', len(glove_word_vectors.vocab))\n",
        "print('embedding dimensionality = ', glove_word_vectors['happy'].shape)"
      ],
      "metadata": {
        "id": "PMAZ6Mx0Tomt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d3918a6-c48b-40e8-85bd-663ee5c7bab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocabulary size =  400000\n",
            "embedding dimensionality =  (100,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "What is embedding exactly?"
      ],
      "metadata": {
        "id": "D8hGE5qYAhb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check word embedding for 'happy'\n",
        "# You can access the embedding of a word with glove_word_vectors[word] if word\n",
        "# is in the vocabulary\n",
        "glove_word_vectors['happy']"
      ],
      "metadata": {
        "id": "bd4n-3nTUp82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78ccba5c-8cab-461d-88de-5d4a72a806fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.090436 ,  0.19636  ,  0.29474  , -0.47706  , -0.80436  ,\n",
              "        0.3078   , -0.55205  ,  0.58453  , -0.17056  , -0.84846  ,\n",
              "        0.19528  ,  0.23671  ,  0.46827  , -0.58977  , -0.12163  ,\n",
              "       -0.24697  , -0.072944 ,  0.17259  , -0.0485   ,  0.9527   ,\n",
              "        0.50629  ,  0.58497  , -0.19367  , -0.45459  , -0.031095 ,\n",
              "        0.51633  , -0.24052  , -0.1007   ,  0.53627  ,  0.024225 ,\n",
              "       -0.50162  ,  0.73692  ,  0.49468  , -0.34744  ,  0.89337  ,\n",
              "        0.057439 , -0.19127  ,  0.39333  ,  0.21182  , -0.89837  ,\n",
              "        0.078704 , -0.16344  ,  0.45261  , -0.41096  , -0.19499  ,\n",
              "       -0.13489  , -0.016313 , -0.021849 ,  0.17136  , -1.2413   ,\n",
              "        0.079503 , -0.91144  ,  0.35699  ,  0.36289  , -0.24934  ,\n",
              "       -2.1196   ,  0.14534  ,  0.52964  ,  0.90134  ,  0.033603 ,\n",
              "        0.022809 ,  0.70625  , -1.0362   , -0.59809  ,  0.70592  ,\n",
              "       -0.072793 ,  0.67033  ,  0.52763  , -0.47807  , -0.67374  ,\n",
              "        0.36632  , -0.38284  , -0.10349  , -0.6402   ,  0.18104  ,\n",
              "        0.82568  ,  0.066403 , -0.40791  , -0.083813 , -0.36487  ,\n",
              "        0.045362 , -0.073527 , -0.20117  ,  0.37441  , -1.4024   ,\n",
              "       -0.25605  , -0.4708   , -0.16145  , -0.87921  , -0.36325  ,\n",
              "       -0.17357  , -0.077983 ,  0.43273  ,  0.0089295, -1.0316   ,\n",
              "       -0.11589  , -0.34524  ,  0.11514  , -0.40812  ,  0.20203  ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With word embeddings learned from GloVe or Word2Vec, words with similar semantic meanings tend to have vectors that are close together. Please code and calculate the **cosine similarities** between words based on their embeddings (i.e., word vectors).\n",
        "\n",
        "For each of the following words in occupation, compute its cosine similarty to 'woman' and its similarity to 'man' and check which gender is more similar. \n",
        "\n",
        "*occupation = {homemaker, nurse, receptionist, librarian, socialite, hairdresser, nanny, bookkeeper, stylist, housekeeper, maestro, skipper, protege, philosopher, captain, architect, financier, warrior, broadcaster, magician}*\n",
        "\n",
        "**Inline Question #1:** \n",
        "- Fill in the table below with cosine similarities between words in occupation list and {woman, man}. Please show only two digits after decimal.\n",
        "- Which words are more similar to 'woman' than to 'man'?\n",
        "- Which words are more similar to 'man' than to 'woman'?\n",
        "- Do you see any issue here? What do you think might cause these issues?\n",
        "\n",
        "**Your Answer:**\n",
        "\n",
        "Words more similar to woman: housemaker, nurse, receptionist, librarian, socialite, hairdresser, nanny, bookkeeper, stylist, housekeeper.\n",
        "Words more similar to man: maestro, skipper, protege, philosopher, captain, architect, financier, warrior, broadcaster, magician. \n",
        "\n",
        "An issue in these cosine similarities is that these embeddings may have been trained on data which may contain biases and stereotypes or might be outdated, which may impact the similarity scores. We can see some of the stereotypes in the scores because jobs such as nurse, homemaker, nanny, etc. are more similar to women while warrior, financier, architect, etc. are more aligned with men. These associations might not accurately reflect the abilities of male or female individuals and can contribute to gender discrimination in various fields.\n",
        "\n",
        "\n",
        "\n",
        "| `similarity`|    woman  |      man     |\n",
        "|-------------|-----------|--------------|\n",
        "| homemaker   |   0.43        |       0.24       |\n",
        "| nurse       |    0.61       |       0.46     |\n",
        "| receptionist|     0.34      |        0.19      |\n",
        "| librarian   |    0.34       |       0.23       |\n",
        "| socialite   |    0.42       |        0.27      |\n",
        "| hairdresser |     0.39      |        0.26      |\n",
        "| nanny       |    0.36       |        0.29      |\n",
        "| bookkeeper  |     0.21      |       0.14       |\n",
        "| stylist     |     0.31      |      0.25        |\n",
        "| housekeeper |     0.46      |        0.31      |\n",
        "| maestro     |   -0.02        |       0.14       |\n",
        "| skipper     |    0.15       |      0.34        |\n",
        "| protege     |     0.12      |       0.2       |\n",
        "| philosopher |   0.23        |      0.28        |\n",
        "| captain     |   0.31        |       0.53       |\n",
        "| architect   |    0.22       |       0.3       |\n",
        "| financier   |     0.14      |        0.26      |\n",
        "| warrior     |    0.39       |      0.51        |\n",
        "| broadcaster |     0.23      |        0.25      |\n",
        "| magician    |    0.27       |      0.38        |\n"
      ],
      "metadata": {
        "id": "V4fKXR-gUQUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# TODO: Fill in your codes                                                     #                                                          #\n",
        "################################################################################\n",
        "occupation = [\"homemaker\", \"nurse\", \"receptionist\", \"librarian\", \"socialite\", \"hairdresser\", \n",
        "              \"nanny\", \"bookkeeper\", \"stylist\", \"housekeeper\", \"maestro\", \"skipper\", \"protege\", \n",
        "              \"philosopher\", \"captain\", \"architect\", \"financier\", \"warrior\", \"broadcaster\", \"magician\"]\n",
        "male_sim = []\n",
        "for i in occupation:\n",
        "  male_sim.append(glove_model.similarity(w1=i, w2='man'))\n",
        "  male_sim2 = [round(i, 2) for i in male_sim]\n",
        "\n",
        "print(f\"man similarity = {male_sim2}\")\n",
        "\n",
        "female_sim = []\n",
        "for i in occupation:\n",
        "  female_sim.append(glove_model.similarity(w1=i, w2='woman'))\n",
        "  female_sim2 = [round(i, 2) for i in female_sim]\n",
        "\n",
        "print(f\"woman similarity = {female_sim2}\")\n"
      ],
      "metadata": {
        "id": "2LKYnnrjjc1B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9478b08a-40c2-49e3-f45a-53b264d7f6c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "man similarity = [0.24, 0.46, 0.19, 0.23, 0.27, 0.26, 0.29, 0.14, 0.25, 0.31, 0.14, 0.34, 0.2, 0.28, 0.53, 0.3, 0.26, 0.51, 0.25, 0.38]\n",
            "woman similarity = [0.43, 0.61, 0.34, 0.34, 0.42, 0.39, 0.36, 0.21, 0.31, 0.46, -0.02, 0.15, 0.12, 0.23, 0.31, 0.22, 0.14, 0.39, 0.23, 0.27]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part II Understand contextual word embedding using BERT (15%)"
      ],
      "metadata": {
        "id": "5tS-rk_0htP1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A big difference between Word2Vec and BERT is that Word2Vec learns context-free word representations, i.e., the embedding for 'orange' is the same in \"I love eating oranges\" and in \"The sky turned orange\". BERT, on the other hand, produces contextual word presentations, i.e., embeddings for the same word in different contexts should be different. \n",
        "\n",
        "For example, let us compare the context-based embedding vectors for 'orange' in the following three sentences using Bert:\n",
        "* \"I love eating oranges\"\n",
        "* \"My favorite fruits are oranges and apples\"\n",
        "* \"The sky turned orange\""
      ],
      "metadata": {
        "id": "qhiqrefnhyzl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Same as in \"Lab 4 Natural Language Processing\", we use the BERT model and tokenizer from the Huggingface transformer library ([1](https://huggingface.co/course/chapter1/1), [2](https://huggingface.co/docs/transformers/quicktour)) "
      ],
      "metadata": {
        "id": "krMUN1bXEHMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers"
      ],
      "metadata": {
        "id": "AE1bsvtolEz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, TFBertModel"
      ],
      "metadata": {
        "id": "IEHtbdMLlS-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the 'bert-base-cased' from Huggingface as the underlying BERT model and the associated tokenizer."
      ],
      "metadata": {
        "id": "6kptKqkSEjAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = TFBertModel.from_pretrained('bert-base-cased')\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
      ],
      "metadata": {
        "id": "VaXbeG1TmukM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f00d69d0-9420-48f1-8ce4-ad6674ff7c5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_sentences = [\"I love eating oranges\",\n",
        "                     \"My favorite fruits are oranges and apples\",\n",
        "                     \"The sky turned orange\"]"
      ],
      "metadata": {
        "id": "Sb_U7kyMEroc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us start by tokenizing the example sentences. "
      ],
      "metadata": {
        "id": "Ftt2mbDnEs6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how Bert tokenize each sentence\n",
        "# This helps us identify the location of 'orange' in the tokenized vector\n",
        "for sen in example_sentences:\n",
        "  print(bert_tokenizer.tokenize(sen))"
      ],
      "metadata": {
        "id": "p4VMvgnCE5MQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d6bbcb7-f8bc-44a8-b621-e762293b0ec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'love', 'eating', 'orange', '##s']\n",
            "['My', 'favorite', 'fruits', 'are', 'orange', '##s', 'and', 'apples']\n",
            "['The', 'sky', 'turned', 'orange']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that the prefix '##' indicates that the token is a continuation of the previous one. This also helps us identify location of 'orange' in the tokenized vector, e.g., 'orange' is the 4th token in the first sentence. Note that here the tokenize() function just splits a text into words, and doesn't add a 'CLS' (classification token) or a 'SEP' (separation token) to the text.\n",
        "\n",
        "Next, we use the tokenizer to transfer the example sentences to input that the Bert model expects. "
      ],
      "metadata": {
        "id": "gDDKRE1RE8OK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_inputs = bert_tokenizer(example_sentences,\n",
        "                             padding=True,\n",
        "                             return_tensors='tf')\n",
        "\n",
        "bert_inputs"
      ],
      "metadata": {
        "id": "u0XgIyKGlqy5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab80e490-bda3-40db-d8a8-ad60eeffebaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(3, 10), dtype=int32, numpy=\n",
              "array([[  101,   146,  1567,  5497,  5925,  1116,   102,     0,     0,\n",
              "            0],\n",
              "       [  101,  1422,  5095, 11669,  1132,  5925,  1116,  1105, 22888,\n",
              "          102],\n",
              "       [  101,  1109,  3901,  1454,  5925,   102,     0,     0,     0,\n",
              "            0]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(3, 10), dtype=int32, numpy=\n",
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(3, 10), dtype=int32, numpy=\n",
              "array([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
              "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "       [1, 1, 1, 1, 1, 1, 0, 0, 0, 0]], dtype=int32)>}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So there are actually three outputs: the input ids (starting with '101' for the '[CLS]' token), the token_type_ids which are usefull when one has distinct segments, and the attention masks which are used to mask out padding tokens. \n",
        "\n",
        "Please refer to our Lab 4 for more details about input_ids, token_type_ids, and attention_masks. \n",
        "\n",
        "More resources:\n",
        "*    https://huggingface.co/docs/transformers/preprocessing\n",
        "*    https://huggingface.co/docs/transformers/tokenizer_summary"
      ],
      "metadata": {
        "id": "CrzU61KaI3Of"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let us get the BERT encoding of our example sentences."
      ],
      "metadata": {
        "id": "6FwSZzTBJFC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_outputs = bert_model(bert_inputs)\n",
        "\n",
        "print('shape of first output: \\t\\t', bert_outputs[0].shape)\n",
        "print('shape of second output: \\t', bert_outputs[1].shape)"
      ],
      "metadata": {
        "id": "vP4sg23im6wd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e29b236-9ef4-4f2d-9446-d345a63660a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of first output: \t\t (3, 10, 768)\n",
            "shape of second output: \t (3, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two outputs here: one with dimensions [3, 10, 768] and one with [3, 768]. The first one [batch_size, sequence_length, embedding_size] is the output of the last layer of the Bert model and are the contextual embeddings of the words in the input sequence. The second output [batch_size, embedding_size] is the embedding of the first token of the sequence (i.e., classification token).\n",
        "\n",
        "Note you can also get the first output through bert_output.last_hidden_state (see below, also check https://huggingface.co/docs/transformers/v4.16.2/en/model_doc/bert#transformers.TFBertModel)\n",
        "\n",
        "We need the first output to get contextualized embeddings for 'orange' in each sentence."
      ],
      "metadata": {
        "id": "x1LmkPOWJPJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_outputs[0]"
      ],
      "metadata": {
        "id": "tZ8FgzC1KWxg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89badd5d-73fc-4304-fd38-16d581e695fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 10, 768), dtype=float32, numpy=\n",
              "array([[[ 0.72526085,  0.10203107, -0.2456913 , ..., -0.04899121,\n",
              "          0.39186493,  0.02921055],\n",
              "        [ 0.22793163,  0.12613113,  0.12215047, ...,  0.310737  ,\n",
              "         -0.13684075,  0.3392896 ],\n",
              "        [ 0.11651912,  0.20991719, -0.62462854, ...,  0.7515278 ,\n",
              "         -0.7327963 ,  0.05906107],\n",
              "        ...,\n",
              "        [-0.10604842, -0.19108056, -0.11248206, ...,  0.13676174,\n",
              "          0.0700283 ,  0.19438447],\n",
              "        [ 0.05706025, -0.29356375, -0.03861137, ...,  0.01286015,\n",
              "          0.27537045,  0.15846874],\n",
              "        [ 0.24304411, -0.06842139,  0.09176363, ..., -0.1619789 ,\n",
              "          0.24152735,  0.00447925]],\n",
              "\n",
              "       [[ 0.5403354 , -0.11092855, -0.12229552, ..., -0.16148913,\n",
              "          0.238005  , -0.0380555 ],\n",
              "        [-0.08707756, -0.13345723,  0.35856643, ..., -0.06155151,\n",
              "          0.13525108,  0.3893334 ],\n",
              "        [-0.01516266, -0.41845638, -0.1303033 , ...,  0.12552258,\n",
              "         -0.49384457,  0.52132285],\n",
              "        ...,\n",
              "        [ 0.28228825, -0.24432173, -0.20267995, ..., -0.09836713,\n",
              "          0.05036372,  0.19456714],\n",
              "        [ 0.41708246,  0.19513264,  0.28022465, ..., -0.45395625,\n",
              "          0.2501219 ,  0.04929551],\n",
              "        [ 0.99297756,  0.24790084, -0.2091465 , ..., -0.6324767 ,\n",
              "          0.18984339, -0.61011505]],\n",
              "\n",
              "       [[ 0.106017  ,  0.06181876,  0.04633295, ..., -0.30906755,\n",
              "          0.23271663, -0.13493448],\n",
              "        [-0.21224612, -0.5082527 ,  0.28352875, ..., -0.06875555,\n",
              "         -0.11457995,  0.5859637 ],\n",
              "        [ 0.08372116,  0.17443322,  0.03233574, ..., -0.21602923,\n",
              "         -0.42035332,  0.1684938 ],\n",
              "        ...,\n",
              "        [-0.40330505, -0.53788483,  0.03425188, ..., -0.04721716,\n",
              "          0.12521876,  0.1538537 ],\n",
              "        [-0.20190921, -0.42219806,  0.01825945, ..., -0.403147  ,\n",
              "          0.4074065 ,  0.04357275],\n",
              "        [-0.18145218, -0.39313826,  0.05961807, ..., -0.31333306,\n",
              "          0.4381908 ,  0.09534106]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_outputs.last_hidden_state"
      ],
      "metadata": {
        "id": "ikEVh5PAJ05j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bb8623e-ebf7-43cf-c15c-ab4b3a357e52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 10, 768), dtype=float32, numpy=\n",
              "array([[[ 0.72526085,  0.10203107, -0.2456913 , ..., -0.04899121,\n",
              "          0.39186493,  0.02921055],\n",
              "        [ 0.22793163,  0.12613113,  0.12215047, ...,  0.310737  ,\n",
              "         -0.13684075,  0.3392896 ],\n",
              "        [ 0.11651912,  0.20991719, -0.62462854, ...,  0.7515278 ,\n",
              "         -0.7327963 ,  0.05906107],\n",
              "        ...,\n",
              "        [-0.10604842, -0.19108056, -0.11248206, ...,  0.13676174,\n",
              "          0.0700283 ,  0.19438447],\n",
              "        [ 0.05706025, -0.29356375, -0.03861137, ...,  0.01286015,\n",
              "          0.27537045,  0.15846874],\n",
              "        [ 0.24304411, -0.06842139,  0.09176363, ..., -0.1619789 ,\n",
              "          0.24152735,  0.00447925]],\n",
              "\n",
              "       [[ 0.5403354 , -0.11092855, -0.12229552, ..., -0.16148913,\n",
              "          0.238005  , -0.0380555 ],\n",
              "        [-0.08707756, -0.13345723,  0.35856643, ..., -0.06155151,\n",
              "          0.13525108,  0.3893334 ],\n",
              "        [-0.01516266, -0.41845638, -0.1303033 , ...,  0.12552258,\n",
              "         -0.49384457,  0.52132285],\n",
              "        ...,\n",
              "        [ 0.28228825, -0.24432173, -0.20267995, ..., -0.09836713,\n",
              "          0.05036372,  0.19456714],\n",
              "        [ 0.41708246,  0.19513264,  0.28022465, ..., -0.45395625,\n",
              "          0.2501219 ,  0.04929551],\n",
              "        [ 0.99297756,  0.24790084, -0.2091465 , ..., -0.6324767 ,\n",
              "          0.18984339, -0.61011505]],\n",
              "\n",
              "       [[ 0.106017  ,  0.06181876,  0.04633295, ..., -0.30906755,\n",
              "          0.23271663, -0.13493448],\n",
              "        [-0.21224612, -0.5082527 ,  0.28352875, ..., -0.06875555,\n",
              "         -0.11457995,  0.5859637 ],\n",
              "        [ 0.08372116,  0.17443322,  0.03233574, ..., -0.21602923,\n",
              "         -0.42035332,  0.1684938 ],\n",
              "        ...,\n",
              "        [-0.40330505, -0.53788483,  0.03425188, ..., -0.04721716,\n",
              "          0.12521876,  0.1538537 ],\n",
              "        [-0.20190921, -0.42219806,  0.01825945, ..., -0.403147  ,\n",
              "          0.4074065 ,  0.04357275],\n",
              "        [-0.18145218, -0.39313826,  0.05961807, ..., -0.31333306,\n",
              "          0.4381908 ,  0.09534106]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we get the embeddings of 'orange' in each sentence by simply finding the 'orange'-token positions in the embedding output and extract the proper components:"
      ],
      "metadata": {
        "id": "b1q3hM3fNiG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orange_1 = bert_outputs[0][0, 4] \n",
        "orange_2 = bert_outputs[0][1, 5]\n",
        "orange_3 = bert_outputs[0][2, 4]\n",
        "\n",
        "oranges = [orange_1, orange_2, orange_3]"
      ],
      "metadata": {
        "id": "Sw1q9s0ZnBkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We calculate pair-wise cosine similarities:"
      ],
      "metadata": {
        "id": "kShV7UfOQMSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_similarities(vecs):\n",
        "    for v_1 in vecs:\n",
        "        similarities = ''\n",
        "        for v_2 in vecs:\n",
        "            similarities += ('\\t' + str(np.dot(v_1, v_2)/\n",
        "                np.sqrt(np.dot(v_1, v_1) * np.dot(v_2, v_2)))[:4])\n",
        "        print(similarities)"
      ],
      "metadata": {
        "id": "W-YfDwiinRf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_similarities(oranges)"
      ],
      "metadata": {
        "id": "4oLzuz8znTBO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9281d1f3-3bc4-4134-c2b7-cdd9cc813aeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t1.0\t0.91\t0.69\n",
            "\t0.91\t1.0\t0.66\n",
            "\t0.69\t0.66\t1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The similarity metrics make sense. The 'orange' in \"The sky turned orange\" is different from the rest. "
      ],
      "metadata": {
        "id": "bB1BRbygpGBM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, please compare the contextual embedding vectors of 'bank' in the following four sentences:\n",
        "\n",
        "\n",
        "*   \"I need to bring my money to the bank today\"\n",
        "*   \"I will need to bring my money to the bank tomorrow\"\n",
        "*   \"I had to bank into a turn\"\n",
        "*   \"The bank teller was very nice\"\n",
        "\n",
        "\n",
        "**Inline Question #1:** \n",
        "\n",
        "- Please calculate the pair-wise cosine similarities between 'bank' in the four sentences and fill in the table below. (Note, bank_i represent bank in the i_th sentence)\n",
        "- Please explain the results. Does it make sense?\n",
        "\n",
        "**Your Answer:**\n",
        "Yes, the results makes sense. We would expect the highest similarities between bank_1 and bank_2 because the context is almost identical. This is shown by the pair-wise similarity of 0.99. We also expect the lowest similarity between bank_3 and the rest of the \"banks\" because it is a verb and the context is the most unrelated in this instance. Sentence 3 has a similarity of just 0.59 with sentences 1 and 2, and 0.62 with sentence four. Finally, \"bank\" in the fourth sentence is highly similar to the first and second bank contexts, with a similarity of 0.87. However, this number is not quite as high as the 0.99 similarity seen between the bank_1 and bank_2 because bank_4 is describing a person who works at a bank, rather than the bank itself.  \n",
        "\n",
        "| `similarity`|  bank_1  |  bank_2  |  bank_3  |  bank_4  |\n",
        "|-------------|----------|----------|----------|----------|\n",
        "| bank_1      |    1.0  |   0.99     |  0.59      |    0.86      |\n",
        "| bank_2      |   0.99       |   1.0       |   0.59   | 0.87      |\n",
        "| bank_3      |   0.59    |     0.59  |   1.0    |    0.62      |\n",
        "| bank_4      |   0.86    |   0.87     |    0.62   |    1.0      |"
      ],
      "metadata": {
        "id": "enG4ADZaqbvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# TODO: Fill in your codes                                                     #                                                              #\n",
        "################################################################################\n",
        "example_sentences = [\"I need to bring my money to the bank today\",\n",
        "                     \"I will need to bring my money to the bank tomorrow\",\n",
        "                     \"I had to bank into a turn\",\n",
        "                     \"The bank teller was very nice\"]\n",
        "for sen in example_sentences:\n",
        "  print(bert_tokenizer.tokenize(sen))\n"
      ],
      "metadata": {
        "id": "WppqV6v_qbHu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4db8a5a1-3db5-4e49-b9bc-e5bd4ea4f2c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'need', 'to', 'bring', 'my', 'money', 'to', 'the', 'bank', 'today']\n",
            "['I', 'will', 'need', 'to', 'bring', 'my', 'money', 'to', 'the', 'bank', 'tomorrow']\n",
            "['I', 'had', 'to', 'bank', 'into', 'a', 'turn']\n",
            "['The', 'bank', 'tell', '##er', 'was', 'very', 'nice']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_inputs = bert_tokenizer(example_sentences,\n",
        "                             padding=True,\n",
        "                             return_tensors='tf')\n",
        "\n",
        "bert_inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ryfFP9T55MS",
        "outputId": "495d832a-570f-4ce6-9502-8fb2956a7589"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(4, 13), dtype=int32, numpy=\n",
              "array([[ 101,  146, 1444, 1106, 2498, 1139, 1948, 1106, 1103, 3085, 2052,\n",
              "         102,    0],\n",
              "       [ 101,  146, 1209, 1444, 1106, 2498, 1139, 1948, 1106, 1103, 3085,\n",
              "        4911,  102],\n",
              "       [ 101,  146, 1125, 1106, 3085, 1154,  170, 1885,  102,    0,    0,\n",
              "           0,    0],\n",
              "       [ 101, 1109, 3085, 1587, 1200, 1108, 1304, 3505,  102,    0,    0,\n",
              "           0,    0]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(4, 13), dtype=int32, numpy=\n",
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(4, 13), dtype=int32, numpy=\n",
              "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
              "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
              "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]], dtype=int32)>}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_outputs = bert_model(bert_inputs)\n",
        "bank_1 = bert_outputs[0][0, 9]\n",
        "bank_2 = bert_outputs[0][1, 10]\n",
        "bank_3 = bert_outputs[0][2, 4]\n",
        "bank_4 = bert_outputs[0][3, 2]\n",
        "banks = [bank_1, bank_2, bank_3, bank_4]\n",
        "cosine_similarities(banks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSBk7rza57lK",
        "outputId": "7f35fc1e-128a-4623-8d43-67a93e031761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t1.0\t0.99\t0.59\t0.86\n",
            "\t0.99\t1.0\t0.59\t0.87\n",
            "\t0.59\t0.59\t1.0\t0.62\n",
            "\t0.86\t0.87\t0.62\t1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part III Text classification\n",
        "\n",
        "In this part, you will build text classifiers that try to infer whether tweets from [@realDonaldTrump](https://twitter.com/realDonaldTrump) were written by Trump himself or by a staff person.\n",
        "This is an example of binary classification on a text dataset. \n",
        "\n",
        "It is known that Donald Trump uses an Android phone, and it has been observed that some of his tweets come from Android while others come from other devices (most commonly iPhone). It is widely believed that Android tweets are written by Trump himself, while iPhone tweets are written by other staff. For more information, you can read this [blog post by David Robinson](http://varianceexplained.org/r/trump-tweets/), written prior to the 2016 election, which finds a number of differences in the style and timing of tweets published under these two devices. (Some tweets are written from other devices, but for simplicity the dataset for this assignment is restricted to these two.)\n",
        "\n",
        "This is a classification task known as \"authorship attribution\", which is the task of inferring the author of a document when the authorship is unknown. We will see how accurately this can be done with linear classifiers using word features.\n",
        "\n",
        "You might find it familiar: Yes! We are using the same data set as your homework 2 from MSBC 5180."
      ],
      "metadata": {
        "id": "muJRiiu1hY4g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tasks\n",
        "\n",
        "In this section, you will build two text classifiers: one with a traditional machine learning method that you studied in MSBC.5190 and one with a deep learning method.\n",
        "\n",
        "\n",
        "*   For the first classifier, you can use any non-deep learning based methods. You can use your solution to Homework 2 of MSBC 5180 here.\n",
        "*   For the second classifier, you may try the following methods\n",
        "    *    Fine-tune BERT (similar to our lab 4 Fine-tune BERT for Sentiment Analysis)\n",
        "    *    Use pre-trained word embedding (useful to check: https://keras.io/examples/nlp/pretrained_word_embeddings/)\n",
        "    *    Train a deep neural network (e.g., RNN, Bi-LSTM) from scratch (similar to notebooks from our textbook: https://github.com/the-deep-learners/deep-learning-illustrated/blob/master/notebooks/bi_lstm_sentiment_classifier.ipynb)\n",
        "\n",
        "You may want to split the current training data to train and validation to help model selection.\n",
        "\n"
      ],
      "metadata": {
        "id": "_qrPDJHAVRSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the Data Set"
      ],
      "metadata": {
        "id": "huC0ZChevyi2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sample code to load raw text###\n",
        "\n",
        "Please download `tweets.train.tsv` and `tweets.test.tsv` from Canvas (Module Assignment) and upload them to Google Colab. Here we load raw text data to text_train and text_test. "
      ],
      "metadata": {
        "id": "vbQbaofDdKJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#training set\n",
        "df_train = pd.read_csv('tweets.train.tsv', sep='\\t', header=None)\n",
        "\n",
        "text_train = df_train.iloc[0:, 1].values.tolist()\n",
        "Y_train = df_train.iloc[0:, 0].values\n",
        "# convert to binary labels (0 and 1)\n",
        "y_train = np.array([1 if v == 'Android' else 0 for v in Y_train])\n",
        "\n",
        "df_test = pd.read_csv('tweets.test.tsv', sep='\\t', header=None)\n",
        "text_test = df_test.iloc[0:, 1].values.tolist()\n",
        "Y_test = df_test.iloc[0:, 0].values\n",
        "# convert to binary labels (0 and 1)\n",
        "y_test = np.array([1 if v == 'Android' else 0 for v in Y_test])"
      ],
      "metadata": {
        "id": "X0LtpZn3mtQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us take a quick look of some training examples"
      ],
      "metadata": {
        "id": "tiwE7oviUIzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_train[:5]"
      ],
      "metadata": {
        "id": "y7x5n1i4U1Ty",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc0e7d86-6eca-48bf-9ca5-7ccc509cfd8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"My statement as to what's happening in Sweden was in reference to a story that was broadcast on _USERNAME_ concerning immigrants & Sweden.\",\n",
              " 'Will be having many meetings this weekend at The Southern White House. Big 5:00 P.M. speech in Melbourne, Florida. A lot to talk about!',\n",
              " \"Don't believe the main stream (fake news) media.The White House is running VERY WELL. I inherited a MESS and am in the process of fixing it.\",\n",
              " 'Looking forward to the Florida rally tomorrow. Big crowd expected!',\n",
              " \"'One of the most effective press conferences I've ever seen!' says Rush Limbaugh. Many agree.Yet FAKE MEDIA calls it differently! Dishonest\"]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[:5]"
      ],
      "metadata": {
        "id": "2MemhkdSU3Uk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9de03a56-9860-4a16-f7ee-956a7ff97614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sample code to preprocess data for BERT ####\n",
        "\n",
        "The pre-processing step is similar to Lab 4. \n",
        "\n",
        "Feel free to dispose it if you want to preprocess the data differently and use methods other than BERT."
      ],
      "metadata": {
        "id": "jcuUb7duU-dL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The longest text in the data is 75 and we use it as the max_length\n",
        "max_length = 75\n",
        "x_train = bert_tokenizer(text_train,\n",
        "              max_length=75,\n",
        "              truncation=True,\n",
        "              padding='max_length', \n",
        "              return_tensors='tf')\n",
        "\n",
        "y_train = np.array([1 if v == 'Android' else 0 for v in Y_train])\n",
        "\n",
        "x_test = bert_tokenizer(text_test,\n",
        "              max_length=75,\n",
        "              truncation=True,\n",
        "              padding='max_length', \n",
        "              return_tensors='tf')\n",
        "\n",
        "y_test = np.array([1 if v == 'Android' else 0 for v in Y_test])"
      ],
      "metadata": {
        "id": "26uqOprdmuj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Your Solution 1: A traditional machine learning approach (30%)"
      ],
      "metadata": {
        "id": "czjHmp3nZPL7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please implement your text classifier using a traditional machine learning method. \n",
        "\n",
        "**Inline Question #1:** \n",
        "- What machine leaning model did you use?\n",
        "- What are the features used in this model?\n",
        "- What is the model's performance in the test data?\n",
        "\n",
        "**Your Answer:**\n",
        "We used a logistic regression model with tf idf. We first transformed the data using a tf idf vectorizer, so the features used in this model include text features extracted using the vectorizer. The features are character-level n-grams (unigrams and bigrams) up to a maximum of 5000 features, after removing stop words in english. The TfidfVectorizer computes the TF-IDF representation of the text, which assigns weights to each feature (n-gram) based on its frequency in the document and across the corpus. The model's performance in the test data is 90.27%.  "
      ],
      "metadata": {
        "id": "N-pI4oKqZapr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# TODO: Fill in your codes                                                     #\n",
        "################################################################################\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2), stop_words='english', use_idf=True)\n",
        "\n",
        "X_train = vectorizer.fit_transform(text_train)\n",
        "X_test = vectorizer.transform(text_test)\n",
        "y_train = np.array([1 if v == 'Android' else 0 for v in Y_train])\n",
        "y_test = np.array([1 if v == 'Android' else 0 for v in Y_test])\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "y_pred = lr.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Test accuracy:', accuracy)"
      ],
      "metadata": {
        "id": "Tkq6TnWfZbSe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff743cad-6214-4c11-e412-aed88132d0b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.9027027027027027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Your Solution 2: A deep learning apporach (30%)\n",
        "\n",
        "Please implement your text classifier using a deep learning method\n",
        "\n",
        "**Inline Question #1:** \n",
        "- What deep leaning model did you use?\n",
        "- Please briefly explain the input, output, and layers (e.g., what does each layer do) of your model. \n",
        "- What is the model's performance in the test data?\n",
        "- Is it better or worse than Solution 1? What might be the cause?\n",
        "\n",
        "**Your Answer:**\n",
        "We chose the bert-base-cased deep learning model. We monitored validation loss and used early stopping to achieve the best accuracy/loss in our validation data. We experimented with smaller/larger learning rates, different batch sizes, and tried using the bert-large-cased model. However, we achieved the highest accuracy with the bert-base-cased model with 7 epochs, a learning rate of 1e-5, and a batch size of 16.  \n",
        "\n",
        "Input: The input of this model is a sequence of word tokens represented by input ids (a sequence of numerical indices representing the words), token type ids (a sequence of numerical indicies indicating which setntence a tooken belongs to), and attention mask (which is a binary variable indicating which tokens are padding tokens vs actual tokens). \n",
        "\n",
        "Output: The output is a probability distribution over two classes in the binary sequence classification task, indicating whether a tweet was written by Trump or an Android. \n",
        "\n",
        "Layers:\n",
        "This model has 12 transformer layers and a classification layer on top of the transformer that maps the final output representation of the [CLS] token to the probability distribution over the two classes. \n",
        "\n",
        "The model's performance in the test data is 92.97%, which is an improvement from the traditional logistic regression machine learning method we used. This might be because BERT can handle longer sequences, it can capture contextual information better, and it has been trained on vast amounts of data, which can be easily be altered for the task at hand. The BERT model was pretrained on BookCorpus, a dataset consisting of 11,038 unpublished books and English Wikipedia. Logistic regression on the other hand, was trained from scratch for the specific task. \n",
        "\n",
        "https://www.analyticsvidhya.com/blog/2021/05/all-you-need-to-know-about-bert/#:~:text=Model%20Overview&text=The%20BERTBase%20model%20uses,has%20around%20110M%20trainable%20parameters. \n",
        "\n",
        "https://huggingface.co/bert-base-cased "
      ],
      "metadata": {
        "id": "1L2f5VzUZThM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModelForSequenceClassification \n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", \n",
        "                                                             num_labels=2)\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=tf.metrics.SparseCategoricalAccuracy(),\n",
        ")"
      ],
      "metadata": {
        "id": "tK7AMp0lZiG3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d860344-25eb-44de-f910-d5dd40e62984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "max_length = 75\n",
        "text_train, text_valid, Y_train, Y_valid = train_test_split(text_train, Y_train, test_size=0.1, random_state=42)\n",
        "\n",
        "x_train = bert_tokenizer(text_train,\n",
        "              max_length=75,\n",
        "              truncation=True,\n",
        "              padding='max_length', \n",
        "              return_tensors='tf')\n",
        "\n",
        "y_train = np.array([1 if v == 'Android' else 0 for v in Y_train])\n",
        "\n",
        "x_valid = bert_tokenizer(text_valid,\n",
        "              max_length=75,\n",
        "              truncation=True,\n",
        "              padding='max_length', \n",
        "              return_tensors='tf')\n",
        "\n",
        "y_valid = np.array([1 if v == 'Android' else 0 for v in Y_valid])\n",
        "\n",
        "\n",
        "x_test = bert_tokenizer(text_test,\n",
        "              max_length=75,\n",
        "              truncation=True,\n",
        "              padding='max_length', \n",
        "              return_tensors='tf')\n",
        "\n",
        "y_test = np.array([1 if v == 'Android' else 0 for v in Y_test])\n"
      ],
      "metadata": {
        "id": "r0N-RD7I_7X0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=4) \n",
        "history = model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "          y_train,\n",
        "          validation_data=([x_valid.input_ids, x_valid.token_type_ids, x_valid.attention_mask], \n",
        "                           y_valid),\n",
        "          epochs=10, \n",
        "          batch_size=16,\n",
        "          callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUKo8xjWvM6m",
        "outputId": "deb28d22-d5a6-468d-c375-a8cb67eb21a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "146/146 [==============================] - 121s 336ms/step - loss: 0.3728 - sparse_categorical_accuracy: 0.8388 - val_loss: 0.2632 - val_sparse_categorical_accuracy: 0.8923\n",
            "Epoch 2/10\n",
            "146/146 [==============================] - 39s 269ms/step - loss: 0.2164 - sparse_categorical_accuracy: 0.9173 - val_loss: 0.2380 - val_sparse_categorical_accuracy: 0.9115\n",
            "Epoch 3/10\n",
            "146/146 [==============================] - 41s 280ms/step - loss: 0.1410 - sparse_categorical_accuracy: 0.9464 - val_loss: 0.2152 - val_sparse_categorical_accuracy: 0.9308\n",
            "Epoch 4/10\n",
            "146/146 [==============================] - 41s 278ms/step - loss: 0.0780 - sparse_categorical_accuracy: 0.9730 - val_loss: 0.2471 - val_sparse_categorical_accuracy: 0.9115\n",
            "Epoch 5/10\n",
            "146/146 [==============================] - 40s 277ms/step - loss: 0.0368 - sparse_categorical_accuracy: 0.9880 - val_loss: 0.3172 - val_sparse_categorical_accuracy: 0.8962\n",
            "Epoch 6/10\n",
            "146/146 [==============================] - 41s 278ms/step - loss: 0.0147 - sparse_categorical_accuracy: 0.9949 - val_loss: 0.2990 - val_sparse_categorical_accuracy: 0.9346\n",
            "Epoch 7/10\n",
            "146/146 [==============================] - 40s 276ms/step - loss: 0.0217 - sparse_categorical_accuracy: 0.9931 - val_loss: 0.3321 - val_sparse_categorical_accuracy: 0.9115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_learning_curve(history):\n",
        "  plt.plot(history.history['sparse_categorical_accuracy'])\n",
        "  plt.plot(history.history['val_sparse_categorical_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'valid'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'valid'], loc='upper left')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "yKm7UiVAzVX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_learning_curve(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "mvp_TUEjBAgq",
        "outputId": "8d35306d-6225-4f35-f2bc-ed54ada94964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(\n",
        "    [x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], \n",
        "    y_test,\n",
        "    batch_size=16)\n",
        "print(f\"Test Loss:{test_loss}\")\n",
        "print(f\"Test Accuracy:{test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EPXQoRgHu-b",
        "outputId": "2f8c92d0-4530-4c2b-fd07-d3b582b5313c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 1s 109ms/step - loss: 0.2301 - sparse_categorical_accuracy: 0.9297\n",
            "Test Loss:0.23006680607795715\n",
            "Test Accuracy:0.929729700088501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final note (10%)\n",
        "\n",
        "Similar to Homework 1, 10% of the total grade is allocated based on model performance. Teams with higher performance scores (max of solution 1 and solution 2) get higher grade. \n",
        "\n"
      ],
      "metadata": {
        "id": "xGYrNIm_JZhb"
      }
    }
  ]
}